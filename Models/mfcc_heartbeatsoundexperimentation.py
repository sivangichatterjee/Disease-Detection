# -*- coding: utf-8 -*-
"""MFCC_HeartBeatSoundExperimentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/115bb-7EnXxMYNopEEhEr6C1AC8rqQqjx
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from io import BytesIO #needed for plot
import seaborn as sns; sns.set()

from keras.models import Model
from keras.layers import LSTM, Dropout, Dense, Conv1D, ConvLSTM2D, Input, Bidirectional, TimeDistributed,GRU
from keras.layers import MaxPooling1D, Flatten, BatchNormalization
from keras.utils import plot_model
from keras.models import load_model
from numpy import save
from numpy import load
import sklearn
from scipy import stats
from sklearn import metrics
from keras.optimizers import Adam, SGD, RMSprop
from keras.models import load_model
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import pickle

from keras.layers import Conv2D, MaxPooling2D, BatchNormalization

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/AI ML Things/University of Turku Research Internship

cd MyDrive/

ls

cd MFCC_features/

ls

X = np.load("x_data_mfcc.npy")
y = np.load("y_data_mfcc.npy")
X = X[:583]
y = y[:583]

def one_hot_target(y):
    
    y_one_hot = pd.get_dummies(y)
    
    return y_one_hot.values

y_ = one_hot_target(y)

## FOR CNN model
train_X = X.reshape(-1,  40, 1)
train_y = y_

### FOR LSTM model
train_X = X.reshape(-1,  40, 1)
train_y = y_

### FOR GRU model 
train_X = X.reshape(-1,  40, 1)
train_y = y_

### FOR CNN+LSTM model and CNN + BiLSTM model
train_X = X.reshape(-1,  40, 1)
train_y = y_

X_train, X_test, y_train, y_test = train_test_split(train_X, train_y ,test_size=0.15, random_state=42, shuffle = True)

def CNN2():

  input_ = Input(shape = ( 40, 1))
  x = (Conv1D(filters = 64, kernel_size = 3, activation = 'relu'))(input_)
  x = (Conv1D(filters =64,kernel_size =  3,activation = 'relu'))(x)
  x = (Dropout(0.1))(x)
  x = (MaxPooling1D(pool_size=2))(x)
  x = (Conv1D(filters =128, kernel_size = 3,activation = 'relu'))(x)
  x = (Conv1D(filters =256,kernel_size = 4,activation ='relu'))(x)
  x = (Dropout(0.2))(x)
  x = (MaxPooling1D(pool_size=2))(x)
  x = (Flatten())(x)
  x = Dense(200, activation = 'relu')(x)
  output = Dense(5, activation = 'softmax')(x)

  model = Model(input_, output)
  
  return model

CNN2()

def LSTM_Model()  : 
    print(y.sum(0))
    input_ = Input(shape = (40,1))
    x = LSTM(40, return_sequences=True)(input_)
    #x = Dropout(0.1)(x)
    x = (LSTM(40, return_sequences= True))(x)
    x = LSTM(40)(x)
    x = Dropout(0.2)(x)
    #x = Dropout(0.2)(x)
    x = Dense(units = 200, activation='relu')(x)
    x = Dense(units = 200, activation='relu')(x)
    x  = Dense(units = 200, activation='relu')(x)
    output = Dense(5,  activation='softmax')(x)

    LSTM_model = Model(input_, output)
    return LSTM_model

LSTM_Model()

def stacked_GRU():

  input_ = Input(shape = (40, 1))
  x = GRU(40, return_sequences =True)(input_)
  x = GRU(40, return_sequences = True)(x)
  x = Dropout(0.2)(x)
  x = GRU(40)(x)
  x = Dense(100, activation = 'relu')(x)
  output = Dense(5, activation = 'softmax')(x)

  GRU_model = Model(input_, output)

  return GRU_model

stacked_GRU()

def CONV_LSTM_model():

    input_ = Input(shape = (40, 1))
    x = (Conv1D(filters=64, kernel_size=3, activation='relu'))(input_)
    x = (Conv1D(filters=64, kernel_size=3, activation='relu'))(x)
    x = (Conv1D(filters=128, kernel_size=3, activation='relu'))(x)
    x = (Dropout(0.2))(x)
    x = (MaxPooling1D(pool_size=2))(x)
    #x = (Flatten())(x)
    x = LSTM(200, return_sequences= True)(x)
    x =LSTM(200, return_sequences=True)(x)
    x = LSTM(200)(x)
    x = Dropout(0.2)(x)
    x = Dense(200, activation='relu')(x)
    output = Dense(5, activation='softmax')(x)

    Conv_LSTM_model = Model(input_, output)

    return Conv_LSTM_model

CONV_LSTM_model()

def CONV_BiLSTM_model():

    input_ = Input(shape = (40, 1))
    x = (Conv1D(filters=64, kernel_size=3, activation='relu'))(input_)
    x = (Conv1D(filters=64, kernel_size=3, activation='relu'))(x)
    x = (Conv1D(filters=128, kernel_size=3, activation='relu'))(x)
    x = (Dropout(0.2))(x)
    x = (MaxPooling1D(pool_size=2))(x)
    #x = TimeDistributed(Flatten())(x)
    x = Bidirectional(LSTM(100, return_sequences= True))(x)
    x = Bidirectional(LSTM(200, return_sequences=True))(x)
    x = LSTM(400)(x)
    x = Dropout(0.2)(x)
    x = Dense(200, activation='relu')(x)
    output = Dense(5, activation='softmax')(x)

    Conv_LSTM_model = Model(input_, output)

    return Conv_LSTM_model

CONV_BiLSTM_model()

def Conv_LSTM2D_model1():
    input_ = Input(shape = ((40,1, 1, 1)))
    x = ConvLSTM2D(filters = 64, kernel_size = (1,3), activation = 'relu')(input_)
    #x = (Conv1D(filters=64, kernel_size=3, activation='relu'))(x)
    x = (Conv1D(filters=128, kernel_size=3, activation='relu'))(x)
    x = (Dropout(0.2))(x)
    x = (MaxPooling1D(pool_size=2))(x)
    x = TimeDistributed(Flatten())(x)
    x = Bidirectional(LSTM(100, return_sequences= True))(x)
    x = LSTM(200)(x)
    x = Dropout(0.2)(x)
    x = Dense(200, activation='relu')(x)
    output = Dense(5, activation='softmax')(x)
    
    
    ConvLSTM2D_model = Model(input_, output)

    return ConvLSTM2D_model

def train_model_(model):
  
  model  = model ### 
  model.compile(loss = 'categorical_crossentropy', optimizer = Adam(), metrics = ['accuracy'])
        

  r = model.fit(X_train, y_train, batch_size = 32, epochs = 30, validation_split = 0.1)
  #return 4, 6
  return model,r

model, r = train_model_(CONV_BiLSTM_model())

def model_evaluate(model, test_X):
    pred = model.predict(test_X)
    y_te = y_test.argmax(axis = 1)
    pred_te = pred.argmax(axis = 1)
    print("CLASSIFICATION REPORT \n")
    print(classification_report(y_te, pred_te))
    print('\n \n')
    print('CONFUSION MATRIX \n')
    print(confusion_matrix(y_te, pred_te))

## Here the model should be trained on X_train only, use that model to test, F1, Kappa etc..
model_evaluate(model, X_test)

def print_performance_metrics():
  
    print('Accuracy:', np.round(metrics.accuracy_score(y_test, max_y_pred_test),4))
    print('Precision:', np.round(metrics.precision_score(y_test, 
                                max_y_pred_test,average='weighted'),4))
    print('Recall:', np.round(metrics.recall_score(y_test, max_y_pred_test,
                                               average='weighted'),4))
    print('F1 Score:', np.round(metrics.f1_score(y_test, max_y_pred_test,
                                               average='weighted'),4))
    print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test.argmax(axis=1), max_y_pred_test.argmax(axis=1)),4))
    print('Matthews Corrcoef:', np.round(metrics.matthews_corrcoef(y_test.argmax(axis=1), max_y_pred_test.argmax(axis=1)),4)) 
    print('ROC AUC:', (metrics.roc_auc_score(y_test, max_y_pred_test,average='macro')))
    print('\t\tClassification Report:\n', metrics.classification_report(y_test, max_y_pred_test))


def print_confusion_matrix_and_save():
    mat = confusion_matrix(y_test.argmax(axis=1), max_y_pred_test.argmax(axis=1))
    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    #plt.show()

    plt.savefig("Hand.jpg")
    # Save SVG in a fake file object.
    f = BytesIO()
    plt.savefig(f, format="svg")

pred_test   = model.predict(X_test)
max_y_pred_test = np.round(pred_test)
print_performance_metrics()

def KFoldCV(train_X,y, model):  # This performs 10 Fold Cross validation on user dependant model

    scores = []
    train_scores = []
    Kfold_CV = KFold(n_splits = 10, random_state=42)
    i = 0

    for train_index, test_index in Kfold_CV.split(train_X):

        #CNN2()
        i += 1
        print(i)
        
          #break
        Conv_LSTM_model  = model
        Conv_LSTM_model.compile(loss = 'categorical_crossentropy', optimizer = Adam(), metrics = ['accuracy'])
        if i<10:
          print(Conv_LSTM_model.summary())

        r = Conv_LSTM_model.fit(train_X[train_index], y[train_index], batch_size = 32, epochs = 30, validation_data = (train_X[test_index],y[test_index]))

        # Evaluate on train
        pred_train = Conv_LSTM_model.predict(train_X[train_index])
        pred_train_te = pred_train.argmax(axis = 1)
        train_te = y[train_index].argmax(axis = 1)
        accuracy_train   = accuracy_score(train_te, pred_train_te)
        train_scores.append(accuracy_train)
        
        # Evaluate on test
        pred  = Conv_LSTM_model.predict(train_X[test_index])
        pred_te = pred.argmax(axis = 1)
        test_te = y[test_index].argmax(axis = 1)
        accuracy = accuracy_score(test_te, pred_te)
        scores.append(accuracy)

    return scores, train_scores, Conv_LSTM_model,r

### This cell performs 10 Cross Validation , to get Accuracy
## Test Accuracy = np.mean(scores)
## Train Accuracy = np.mean(train_scores)
scores, train_scores, model, r = KFoldCV(train_X,train_y, CONV_BiLSTM_model()) ## Write model type as third parameter

np.mean(scores)   ###10Fold Test Sccuracy

np.mean(train_scores) ###10Fold Train Accuracy

